import{_ as e,c as a,o as i,a1 as l}from"./chunks/framework.DCKU21so.js";const r="/assets/1.B9EzMG0Z.png",n="/assets/2.CTIOzEqS.png",s="/assets/3.DzXbl3RA.png",m=JSON.parse('{"title":"普通索引和唯一索引","description":"","frontmatter":{},"headers":[],"relativePath":"DATABASE/MySQL/chap08.md","filePath":"DATABASE/MySQL/chap08.md"}'),t={name:"DATABASE/MySQL/chap08.md"},o=l('<h1 id="普通索引和唯一索引" tabindex="-1">普通索引和唯一索引 <a class="header-anchor" href="#普通索引和唯一索引" aria-label="Permalink to &quot;普通索引和唯一索引&quot;">​</a></h1><p>举例说明：假设字段k上的值都不重复。InnoDB的索引组织结构如下所示：</p><p><img src="'+r+'" alt="image"></p><p>以下主要从性能的角度来考虑采用唯一索引还是普通索引？（查询语句和更新语句）</p><h2 id="查询过程" tabindex="-1">查询过程 <a class="header-anchor" href="#查询过程" aria-label="Permalink to &quot;查询过程&quot;">​</a></h2><p>假设，执行查询的语句是 select id from T where k=5；这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。</p><ul><li>对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，<strong>需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录</strong>。</li><li>对于唯一索引来说，由于索引定义了唯一性，<strong>查找到第一个满足条件的记录后，就会停止继续检索</strong>。</li></ul><p>这两种索引方式在查询过程中性能差距微乎其微，原因是：</p><ul><li>InnoDB 的数据是按数据页为单位来读写的，当找到 k=5 的记录的时候，它所在的数据页就都在内存里了。</li><li>对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。</li></ul><h2 id="更新过程" tabindex="-1">更新过程 <a class="header-anchor" href="#更新过程" aria-label="Permalink to &quot;更新过程&quot;">​</a></h2><h3 id="change-buffer" tabindex="-1">change buffer <a class="header-anchor" href="#change-buffer" aria-label="Permalink to &quot;change buffer&quot;">​</a></h3><ul><li>当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会<strong>将这些更新操作缓存在 change buffer 中</strong>，这样就不需要从磁盘中读入这个数据页了</li><li>在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作</li><li>change buffer是可以持久化的数据，即change buffer 在内存中有拷贝，也会被写入到磁盘上</li><li><strong>将 change buffer 中的操作应用到原数据页</strong>，得到最新结果的过程称为 merge</li><li>除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。</li></ul><p>change buffer的<strong>使用条件</strong>：</p><ul><li>唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用</li><li>change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。</li></ul><p>如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程如下：</p><ol><li>这个记录要更新的目标页在内存中。InnoDB 的处理流程如下：</li></ol><ul><li>对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；</li><li>对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。</li></ul><ol start="2"><li>这个记录要更新的目标页不在内存中。InnoDB 的处理流程如下：</li></ol><ul><li>对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；</li><li>对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。</li></ul><p><mark>唯一索引由于需要将数据从磁盘读取内存，导致其更新操作耗费巨大；而普通索引运用change buffer，减少了随机磁盘访问，提升更新性能。</mark></p><h2 id="change-buffer的使用场景" tabindex="-1">change buffer的使用场景 <a class="header-anchor" href="#change-buffer的使用场景" aria-label="Permalink to &quot;change buffer的使用场景&quot;">​</a></h2><p>change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。</p><ul><li>因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是<strong>账单类、日志类的系统</strong>。</li><li>而对于更新模式为写入之后马上会做查询的业务模式，随机访问 IO 的次数不会减少，<strong>反而增加了 change buffer 的维护代价</strong>，change buffer 反而起到了副作用。</li></ul><h2 id="索引选择和实践" tabindex="-1">索引选择和实践 <a class="header-anchor" href="#索引选择和实践" aria-label="Permalink to &quot;索引选择和实践&quot;">​</a></h2><ul><li>尽量选择普通索引，在实际使用中，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的</li><li>如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。</li><li>特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的：把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。</li></ul><h2 id="change-buffer-和-redo-log" tabindex="-1">change buffer 和 redo log <a class="header-anchor" href="#change-buffer-和-redo-log" aria-label="Permalink to &quot;change buffer 和 redo log&quot;">​</a></h2><p>现执行插入语句，如下所示：</p><div class="language-sql vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sql</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">mysql</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> insert into</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> t(id,k) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">values</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(id1,k1),(id2,k2);</span></span></code></pre></div><p>假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中。带 change buffer 的更新状态图如下所示：</p><p><img src="'+n+'" alt="image"></p><p>该操作涉及四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）</p><p>这条更新语句做了如下的操作（按照图中的数字顺序）：</p><ol><li>Page 1 在内存中，直接更新内存；</li><li>Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息；</li><li>将上述两个动作记入 redo log 中（图中 3 和 4）。</li></ol><p><strong>注</strong>：图中的两个虚线箭头，是后台操作，不影响更新的响应时间。</p><p>当在这个操作之后进行相应的读操作：select * from t where k in (k1, k2)。则带change buffer的读操作流程图如下所示：</p><p><img src="'+s+'" alt="image"></p><ol><li>读 Page 1 的时候，直接从内存返回。</li><li>要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，<strong>然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果</strong>。</li></ol><p>因此，如果要简单地对比这两个机制在提升更新性能上的收益的话，<mark>redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。</mark></p>',38),h=[o];function f(g,c,u,p,b,d){return i(),a("div",null,h)}const _=e(t,[["render",f]]);export{m as __pageData,_ as default};
